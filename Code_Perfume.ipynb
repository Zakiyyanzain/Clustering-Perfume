{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OVqZEON1bWZ"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sat Sep 28 12:55:47 2024\n",
        "\n",
        "@author: ACER\n",
        "\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import seaborn as sns\n",
        "import googlemaps\n",
        "from geopy.geocoders import Nominatim\n",
        "from sklearn.cluster import KMeans\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "# %%\n",
        "\n",
        "df = pd.read_csv(r'E:\\Programming Python\\ebay_mens_perfume.csv')\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "# Remove rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "print(df.dtypes)\n",
        "# Check for duplicate rows\n",
        "duplicates = df.duplicated()\n",
        "#Menghapus data 'unbranded'\n",
        "df = df[df['brand'] != 'Unbranded']\n",
        "# Print the number of duplicate rows\n",
        "print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
        "# Print the duplicate rows\n",
        "print(df[duplicates])\n",
        "# Menghapus row data yang memiliki isi yang tidak dibutuhkan\n",
        "df = df[df['type'] != 'Does Not Apply']\n",
        "df = df[df['type'] != 'Does not apply']\n",
        "df = df[df['type'] != 'Eau de Parfum/Eau de Toilette']\n",
        "df = df[df['type'] != 'Eau de Parfum/ Eau de Toilette']\n",
        "df = df[df['type'] != 'Eau de Toilette, Cologne Spray']\n",
        "df = df[df['type'] != 'Pheromone']\n",
        "df = df[df['type'] != 'Y']\n",
        "df = df[df['type'] != 'Various']\n",
        "df = df[df['type'] != 'Roll On']\n",
        "df = df[df['type'] != 'Splash-on']\n",
        "df = df[df['type'] != 'Deodorant']\n",
        "\n",
        "#mengelompokkan berdasarkan brand\n",
        "df['brand'] = df['brand'].str.lower()\n",
        "grouped_brands = df.groupby('brand')\n",
        "print(grouped_brands)\n",
        "df = df[df['brand'] != 'as picture show']\n",
        "df = df[df['brand'] != 'as picture shown']\n",
        "df = df[df['brand'] != 'as show']\n",
        "df = df[df['brand'] != 'as showed']\n",
        "df = df[df['brand'] != 'as shown']\n",
        "df = df[df['brand'] != 'cologne']\n",
        "df = df[df['brand'] != 'multiple brands']\n",
        "df = df[df['brand'] != 'fragrance']\n",
        "df = df[df['brand'] != 'classic brands']\n",
        "\n",
        "mapping = {\n",
        "    'EDT': 'Eau De Toilette',\n",
        "    'edt': 'Eau De Toilette',\n",
        "    'Eau De Toilette': 'Eau De Toilette',\n",
        "    'Eau de Toilette': 'Eau De Toilette',\n",
        "    'Eau de Toillette': 'Eau De Toilette',\n",
        "    'Eau de toilette': 'Eau De Toilette',\n",
        "    'Eau de Toilette Intense': 'Eau De Toilette Intense',\n",
        "    'Cologne spray': 'Eau De Cologne',\n",
        "    'Cologne': 'Eau De Cologne',\n",
        "    'DIOR HOMME COLOGNE': 'Eau De Cologne',\n",
        "    'Eau De Cologne': 'Eau De Cologne',\n",
        "    'EDC': 'Eau De Cologne',\n",
        "    'Eau de Cologne Spray, Cologne Spray': 'Eau De Cologne',\n",
        "    'Fine Cologne': 'Eau De Cologne',\n",
        "    'cologne': 'Eau De Cologne',\n",
        "    'Eau de Cologne':'Eau De Cologne',\n",
        "    'Concentrated Uncut Pure Body Oil': 'Body Oil',\n",
        "    'Body Oil': 'Body Oil',\n",
        "    'Oil': 'Body Oil',\n",
        "    'De Nuit': 'Eau De Parfum',\n",
        "    'Eau De Parfume':'Eau De Parfum',\n",
        "    'Eau de Parfume':'Eau De Parfum',\n",
        "    'Eau de Parfume':'Eau De Parfum',\n",
        "    'Eau de Perfume':'Eau De Parfum',\n",
        "    'Eau de Parfum':'Eau De Parfum',\n",
        "    'Editions Parfums':'Eau De Parfum',\n",
        "    'LE PARFUM':'Eau De Parfum',\n",
        "    'le parfum':'Eau De Parfum',\n",
        "    'Eau De Parfum':'Eau De Parfum',\n",
        "    '~ THE ONE EAU DE PARFUM SPRAY ~':'Eau De Parfum',\n",
        "    'PARFUM':'Eau De Parfum',\n",
        "    'Parfum':'Eau De Parfum',\n",
        "    'Perfume':'Eau De Parfum',\n",
        "    'Eau De Parfume Intense':'Eau De Parfum Intense',\n",
        "    'Eau de Parfume Intense':'Eau De Parfum Intense',\n",
        "    'Eau De Parfum Intense':'Eau De Parfum Intense',\n",
        "    'Parfum Intense':'Eau De Parfum Intense',\n",
        "    'Eau de Parfum Intense':'Eau De Parfum Intense',\n",
        "    'Elixir': 'Elixir',\n",
        "    'EXTRAIT DE PARFUM':'Extrait De Parfum',\n",
        "    'Extrait De Parfum':'Extrait De Parfum',\n",
        "    'Fragrance Body Spray': 'Fragrance',\n",
        "    'Fragrance Rolling Ball': 'Fragrance',\n",
        "    'Fragrances':'Fragrance',\n",
        "    'Body Spray':'Fragrance',\n",
        "    'Gift Sets':'Gift Sets',\n",
        "    'jo Malone Cologne Intense Spray': 'Cologne Intense',\n",
        "    'Jo Malone Cologne Intense Spray':'Cologne Intense',\n",
        "    'Unscented':'Unscented',\n",
        "    'Aftershave':'Aftershave',\n",
        "    # tambahkan nilai-nilai lain yang perlu di-mapping\n",
        "}\n",
        "\n",
        "# Menggunakan metode map() untuk mengganti nilai-nilai yang tidak konsisten\n",
        "df['type 2'] = df['type'].map(mapping)\n",
        "# Mengelompokkan data berdasarkan harga dan jenis\n",
        "df_grouped = df.groupby(['type 2', 'price'])\n",
        "# Melakukan agregasi pada data yang telah dikelompokkan\n",
        "df_aggregated = df_grouped.agg({'price': 'mean'})\n",
        "#Cek NaN Values di kolom type 2\n",
        "nan_values = df[df['type 2'].isnull()]\n",
        "print(nan_values['type'])\n",
        "\n",
        "# Membuat dictionary untuk mapping nilai-nilai yang tidak konsisten\n",
        "mappingbrand = {\n",
        "    'dolce & gabbana': 'dolce & gabbana',\n",
        "    'dolce&gabbana': 'dolce & gabbana',\n",
        "    '~ dolce & gabbana ~':'dolce & gabbana',\n",
        "    'estee lauder': 'estee lauder',\n",
        "    'estée lauder': 'estee lauder',\n",
        "    'acqua di gio':'giorgio armani',\n",
        "    'guerlain':'guerlain',\n",
        "    'guerlain paris':'guerlain',\n",
        "    'hermes':'hermes',\n",
        "    'hermès':'hermes',\n",
        "    'kenneth cole':'kenneth cole reaction',\n",
        "    'mercedes-benz':'mercedes benz',\n",
        "    'michael malul gents scents':'michael malul',\n",
        "    'michael malul london':'michael malul',\n",
        "    'montblanc':'mont blanc',\n",
        "    'polo':'polo ralph lauren',\n",
        "    'ralph lauren':'polo ralph lauren',\n",
        "    'roja dove':'roja',\n",
        "    'roja parfums':'roja',\n",
        "    'victor & rolf':'viktor & rolf',\n",
        "\n",
        "}\n",
        "df['brand_lower'] = df['brand'].map(lambda x: mappingbrand.get(x.lower(), x))\n",
        "\n",
        "# Menampilkan hasil agregasi dalam bentuk grafik\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.bar(df_aggregated.index.get_level_values(0), df_aggregated['price'], color=plt.cm.tab20(np.linspace(0, 1, len(df_aggregated))))\n",
        "plt.title('Average Price by Type')\n",
        "plt.xlabel('Type')\n",
        "plt.xticks(fontsize=8, rotation=90)\n",
        "plt.ylabel('Average Price')\n",
        "plt.show()\n",
        "\n",
        "df['jumlah_koma']=df['itemLocation'].apply(lambda x: x.count(','))\n",
        "print(df['jumlah_koma'])\n",
        "max_koma = df['jumlah_koma'].max()\n",
        "print(\"Jumlah koma terbanyak:\", max_koma)\n",
        "# tambahkan ',' pada setiap baris data yang belum memiliki ',' berjumlah 3 sebelum kata pertama\n",
        "df['itemLocation'] = df.apply(lambda row: ',' * (3 - row['jumlah_koma']) + row['itemLocation'] if row['jumlah_koma'] < 3 else row['itemLocation'], axis=1)\n",
        "print(df['itemLocation'])\n",
        "\n",
        "df['kota'] = df.apply(lambda row: row['itemLocation'].split(',')[1] if len(row['itemLocation'].split(',')) > 1 and row['itemLocation'].split(',')[1] != '' else row['itemLocation'].split(',')[2], axis=1)\n",
        "print(df['kota'])\n",
        "jumlah_kosong = df['kota'].isnull().sum() + df['kota'].apply(lambda x: x.strip() == '').sum()\n",
        "print(\"Jumlah nilai kosong:\", jumlah_kosong)\n",
        "#menghapus baris data yang memiliki nilai string kosong (''), None, atau NaN pada kolom isi_setelah_koma_1\n",
        "df = df[df['kota'].apply(lambda x: x.strip() != '' and x is not None and not pd.isnull(x))]\n",
        "print(df)\n",
        "df = df.sort_values(by='kota')\n",
        "print(df)\n",
        "print(df['sold'])\n",
        "\n",
        "# %% PEMISAHAN DATA NORMAL DAN OUTLIER\n",
        "\n",
        "\n",
        "# Definisikan kolom numerik\n",
        "kolom_numerik = ['price', 'available', 'sold']\n",
        "threshold = 3\n",
        "# Buat dataframe untuk DATA NORMAL dan outlier\n",
        "df_normal = df.copy()\n",
        "df_outliers = pd.DataFrame()\n",
        "\n",
        "for kolom in kolom_numerik:\n",
        "    z_scores = np.abs(stats.zscore(df[kolom]))\n",
        "    outlier_index = df[z_scores > threshold].index\n",
        "    df_normal = df_normal.drop(outlier_index, errors='ignore')\n",
        "    df_outliers = pd.concat([df_outliers, df.loc[outlier_index]])\n",
        "\n",
        "# Buat figure dan axis\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plot distribusi price\n",
        "axs[0].hist(df_normal['price'], bins=10, alpha=0.5, label='Normal')\n",
        "axs[0].hist(df_outliers['price'], bins=10, alpha=0.5, label='Outlier')\n",
        "axs[0].set_title('Price Distribution')\n",
        "axs[0].set_xlabel('Price')\n",
        "axs[0].set_ylabel('Frequency')\n",
        "axs[0].legend()\n",
        "\n",
        "# Plot distribusi available\n",
        "axs[1].hist(df_normal['available'], bins=10, alpha=0.5, label='Normal')\n",
        "axs[1].hist(df_outliers['available'], bins=10, alpha=0.5, label='Outlier')\n",
        "axs[1].set_title('Available Distribution')\n",
        "axs[1].set_xlabel('Available')\n",
        "axs[1].set_ylabel('Frequency')\n",
        "axs[1].legend()\n",
        "\n",
        "# Plot distribusi sold\n",
        "axs[2].hist(df_normal['sold'], bins=10, alpha=0.5, label='Normal')\n",
        "axs[2].hist(df_outliers['sold'], bins=10, alpha=0.5, label='Outlier')\n",
        "axs[2].set_title('Sold Distribution')\n",
        "axs[2].set_xlabel('Sold')\n",
        "axs[2].set_ylabel('Frequency')\n",
        "axs[2].legend()\n",
        "\n",
        "# Tampilkan plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analisis data normal\n",
        "print(\"Analisis Data Normal:\")\n",
        "print(df_normal.describe())\n",
        "print(df_normal.info())\n",
        "# Analisis data outlier\n",
        "print(\"Analisis Data Outlier:\")\n",
        "print(df_outliers.describe())\n",
        "print(df_outliers.info())\n",
        "\n",
        "\n",
        "\n",
        "# Visualisasi distribusi data normal dan outlier\n",
        "for kolom in kolom_numerik:\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.hist(df_normal[kolom], bins=10, alpha=0.5, label='Data Normal')\n",
        "    plt.hist(df_outliers[kolom], bins=10, alpha=0.5, label='Data Outlier')\n",
        "    plt.title(f'{kolom} Distribution')\n",
        "    plt.xlabel(kolom)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Analisis korelasi antara kolom pada data normal dan outlier\n",
        "for kolom1 in kolom_numerik:\n",
        "    for kolom2 in kolom_numerik:\n",
        "        if kolom1 != kolom2:\n",
        "            plt.figure(figsize=(10,6))\n",
        "            plt.scatter(df_normal[kolom1], df_normal[kolom2], label='Data Normal')\n",
        "            plt.scatter(df_outliers[kolom1], df_outliers[kolom2], label='Data Outlier')\n",
        "            plt.title(f'Correlation between {kolom1} and {kolom2}')\n",
        "            plt.xlabel(kolom1)\n",
        "            plt.ylabel(kolom2)\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "# Identify outliers using the Z-score method\n",
        "for kolom in kolom_numerik:\n",
        "    z_scores = np.abs(stats.zscore(df[kolom]))\n",
        "    print(f\"Z-scores untuk {kolom}:\")\n",
        "    print(z_scores)\n",
        "# Definisikan threshold\n",
        "threshold = 3\n",
        "# Identifikasi outlier\n",
        "for kolom in kolom_numerik:\n",
        "    z_scores = np.abs(stats.zscore(df[kolom]))\n",
        "    outlier = df[(z_scores > threshold)]\n",
        "    print(f\"Outlier untuk {kolom}:\")\n",
        "    print(outlier)\n",
        "# Buat boxplot outliers\n",
        "for kolom in kolom_numerik:\n",
        "    plt.boxplot(df[kolom])\n",
        "    plt.title(f\"Boxplot {kolom}\")\n",
        "    plt.show()\n",
        "\n",
        "# Analisis distribusi jumlah penjualan\n",
        "plt.hist(df['sold'], bins=10)\n",
        "plt.title('Sales Quantity Distribution')\n",
        "plt.xlabel('Sales Quantity')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Analisis korelasi antara jumlah penjualan dan harga\n",
        "plt.scatter(df['sold'], df['price'])\n",
        "plt.title('Correlation between Sales Volume and Price')\n",
        "plt.xlabel('Sales Quantity')\n",
        "plt.ylabel('Price')\n",
        "plt.show()\n",
        "\n",
        "# Analisis segmentasi pelanggan berdasarkan jumlah penjualan\n",
        "df_segmentasi = df.groupby('sold')['price'].mean()\n",
        "plt.bar(df_segmentasi.index, df_segmentasi.values)\n",
        "plt.title('Customer Segmentation Analysis')\n",
        "plt.xlabel('Sales Quantity')\n",
        "plt.ylabel('Average Price')\n",
        "plt.show()\n",
        "\n",
        "df['jumlah_koma']=df['itemLocation'].apply(lambda x: x.count(','))\n",
        "print(df['jumlah_koma'])\n",
        "max_koma = df['jumlah_koma'].max()\n",
        "print(\"Jumlah koma terbanyak:\", max_koma)\n",
        "# tambahkan ',' pada setiap baris data yang belum memiliki ',' berjumlah 3 sebelum kata pertama\n",
        "df['itemLocation'] = df.apply(lambda row: ',' * (3 - row['jumlah_koma']) + row['itemLocation'] if row['jumlah_koma'] < 3 else row['itemLocation'], axis=1)\n",
        "print(df['itemLocation'])\n",
        "# %%\n",
        "\n",
        "\n",
        "#Clustering Dbscan data normal\n",
        "dv = df_normal['sold'].values\n",
        "dr = dv.reshape(-1, 1)\n",
        "print(dr.shape)  # (5, 1)\n",
        "print(dr)\n",
        "scaler = StandardScaler()\n",
        "df_scaled = scaler.fit_transform(dr)\n",
        "# Replace KMeans with DBSCAN\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "dbscan.fit(df_scaled)\n",
        "labels = dbscan.labels_\n",
        "print(labels)\n",
        "\n",
        "# Add cluster labels to DataFrame\n",
        "df_normal['cluster_label'] = labels\n",
        "# --- Filtering out noise points for visualization ---\n",
        "df_clustered = df_normal[df_normal['cluster_label'] != -1] # Create a new DataFrame without noise points\n",
        "labels_clustered = df_clustered['cluster_label'] # Get labels for clustered points only\n",
        "# Visualizing clusters without noise points\n",
        "plt.figure(figsize=(8, 6))\n",
        "# Using a for loop to plot each cluster (excluding noise)\n",
        "for i in np.unique(labels_clustered):\n",
        "    plt.hist(df_clustered[labels_clustered == i]['price'], bins=10, alpha=0.5, label=f'Cluster {i+1}')\n",
        "\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('DBSCAN Clustering Results (Noise Excluded)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# --- Visualizing with boxplots (excluding noise) ---\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='cluster_label', y='price', data=df_clustered)\n",
        "plt.title('Price Distribution per Cluster (Noise Excluded)')\n",
        "plt.show()\n",
        "# --- Visualizing with boxplots (excluding noise) ---\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='cluster_label', y='available', data=df_clustered)\n",
        "plt.title('Available Distribution per Cluster (Noise Excluded)')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "silhouette_scores = []\n",
        "for eps in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
        "    dbscan = DBSCAN(eps=eps, min_samples=5)\n",
        "    labels = dbscan.fit_predict(df_scaled)\n",
        "    silhouette_avg = silhouette_score(df_scaled, labels)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "    print(f\"For eps = {eps}, The average silhouette score is : {silhouette_avg:.3f}\")\n",
        "\n",
        "plt.plot(range(1, 11), silhouette_scores)\n",
        "plt.xlabel('Eps')\n",
        "plt.ylabel('Silhouette score')\n",
        "plt.title('Silhouette score vs eps')\n",
        "plt.show()\n",
        "\n",
        "# Membagi data df menjadi beberapa cluster berdasarkan labels\n",
        "clusters = []\n",
        "for i in np.unique(labels):\n",
        "    cluster_data = df_normal[labels == i]\n",
        "    clusters.append(cluster_data)\n",
        "# Menganalisis info yang ada pada setiap cluster\n",
        "for i, cluster in enumerate(clusters):\n",
        "    print(f\"Cluster {i+1}:\")\n",
        "    print(cluster.describe())\n",
        "    print(cluster.info())\n",
        "\n",
        "for i, cluster in enumerate(clusters):\n",
        "    print(f\"Cluster {i+1}:\")\n",
        "    print(f\"  Amount of Data: {len(cluster)}\")\n",
        "    print(f\"  Average by Price: {cluster['price'].mean():.2f}\")\n",
        "    print(f\"  Average by Sold: {cluster['sold'].mean():.2f}\")  # tambahkan baris ini\n",
        "    print(f\"  Dominant Brand: {cluster['brand_lower'].mode()[0]}\")  # Merek yang paling sering muncul\n",
        "    print(f\"  Dominant parfume types: {cluster['type 2'].mode()[0]}\") # Jenis yang paling sering muncul\n",
        "    print(f\"  Dominant Location: {cluster['kota'].mode()[0]}\")\n",
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame that summarizes the cluster information\n",
        "cluster_info = pd.DataFrame({\n",
        "    'Cluster': ['Cluster 1', 'Cluster 2'],\n",
        "    'Amount of Data': [len(clusters[0]), len(clusters[1])],\n",
        "    'Average by Price': [clusters[0]['price'].mean(), clusters[1]['price'].mean()],\n",
        "    'Average by Sold': [clusters[0]['sold'].mean(), clusters[1]['sold'].mean()],\n",
        "    'Dominant Brand': [clusters[0]['brand_lower'].mode()[0], clusters[1]['brand_lower'].mode()[0]],\n",
        "    'Dominant Parfume Types': [clusters[0]['type 2'].mode()[0], clusters[1]['type 2'].mode()[0]],\n",
        "    'Dominant Location': [clusters[0]['kota'].mode()[0], clusters[1]['kota'].mode()[0]]\n",
        "})\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Hide the axis\n",
        "ax.axis('off')\n",
        "\n",
        "# Create a table\n",
        "ax.table(cellText=cluster_info.values, colLabels=cluster_info.columns, loc='center')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# ... (DBSCAN fitting and getting labels)\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "dbscan.fit(df_scaled)\n",
        "labels = dbscan.labels_\n",
        "\n",
        "#Evaluasi Model\n",
        "silhouette = silhouette_score(df_scaled, labels)\n",
        "davies_bouldin = davies_bouldin_score(df_scaled, labels)\n",
        "print(f\"Silhouette Score: {silhouette:.3f}\")\n",
        "print(f\"Davies-Bouldin Index: {davies_bouldin:.3f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# %%\n",
        "\n",
        "\n",
        "#Clustering Dbscan pada data outlier\n",
        "dv = df_outliers['sold'].values\n",
        "dr = dv.reshape(-1, 1)\n",
        "print(dr.shape)  # (5, 1)\n",
        "print(dr)\n",
        "scaler = StandardScaler()\n",
        "df_scaled_outliers = scaler.fit_transform(dr)\n",
        "# Replace KMeans with DBSCAN\n",
        "dbscan_outliers = DBSCAN(eps=0.5, min_samples=5)\n",
        "dbscan_outliers.fit(df_scaled_outliers)\n",
        "labels_outliers = dbscan_outliers.labels_\n",
        "print(labels_outliers)\n",
        "\n",
        "# Add cluster labels to DataFrame\n",
        "df_outliers['cluster_label'] = labels_outliers\n",
        "# --- Filtering out noise points for visualization ---\n",
        "df_clustered_outliers = df_outliers[df_outliers['cluster_label'] != -1] # Create a new DataFrame without noise points\n",
        "labels_clustered_outliers = df_clustered_outliers['cluster_label'] # Get labels for clustered points only\n",
        "# Visualizing clusters without noise points\n",
        "plt.figure(figsize=(8, 6))\n",
        "# Using a for loop to plot each cluster (excluding noise)\n",
        "for i in np.unique(labels_clustered_outliers):\n",
        "    plt.hist(df_clustered_outliers[labels_clustered_outliers == i]['price'], bins=10, alpha=0.5, label=f'Cluster {i+1}')\n",
        "\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('DBSCAN Clustering Results (Noise Excluded) - Outliers')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# --- Visualizing with boxplots (excluding noise) ---\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='cluster_label', y='price', data=df_clustered_outliers)\n",
        "plt.title('Price Distribution per Cluster (Noise Excluded) - Outliers')\n",
        "plt.show()\n",
        "# --- Visualizing with boxplots (excluding noise) ---\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='cluster_label', y='available', data=df_clustered_outliers)\n",
        "plt.title('Available Distribution per Cluster (Noise Excluded) - Outliers')\n",
        "plt.show()\n",
        "\n",
        "# Membagi data df menjadi beberapa cluster berdasarkan labels\n",
        "clusters_outliers = []\n",
        "for i in np.unique(labels_outliers):\n",
        "    cluster_data = df_outliers[labels_outliers == i]\n",
        "    clusters_outliers.append(cluster_data)\n",
        "# Menganalisis info yang ada pada setiap cluster\n",
        "for i, cluster in enumerate(clusters_outliers):\n",
        "    print(f\"Cluster {i+1}:\")\n",
        "    print(cluster.describe())\n",
        "    print(cluster.info())\n",
        "\n",
        "for i, cluster in enumerate(clusters_outliers):\n",
        "    print(f\"Cluster {i+1}:\")\n",
        "    print(f\"  Amount of Data: {len(cluster)}\")\n",
        "    print(f\"  Average by Price: {cluster['price'].mean():.2f}\")\n",
        "    print(f\"  Average by Sold: {cluster['sold'].mean():.2f}\")  # tambahkan baris ini\n",
        "    print(f\"  Dominant Brand: {cluster['brand_lower'].mode()[0]}\")  # Merek yang paling sering muncul\n",
        "    print(f\"  Dominant parfume types: {cluster['type 2'].mode()[0]}\") # Jenis yang paling sering muncul\n",
        "    print(f\"  Dominant Location: {cluster['kota'].mode()[0]}\")\n",
        "\n",
        "print(' ')\n",
        "print(' ')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# %%\n",
        "#REGRESI\n",
        "\n",
        "\n",
        "# Definisikan variabel independen (X)\n",
        "X = df_normal[['available', 'price']]\n",
        "\n",
        "# Hitung VIF\n",
        "vif = pd.DataFrame()\n",
        "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "vif[\"features\"] = X.columns\n",
        "\n",
        "# Tampilkan hasil VIF\n",
        "print(vif)\n",
        "\n",
        "# Buat Correlation Matrix\n",
        "corr_matrix = X.corr()\n",
        "print(corr_matrix)\n",
        "\n",
        "# Visualisasi Correlation Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', square=True)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Definisikan variabel independen (X) dan dependen (y)\n",
        "X = df_normal[['available', 'price']]\n",
        "y = df_normal['sold']\n",
        "\n",
        "# Split data menjadi training dan testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Buat model regresi linear\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train model dengan data training\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi harga dengan data testing\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluasi model dengan mean squared error dan r2 score\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"R2 Score: {r2:.2f}\")\n",
        "\n",
        "# Tampilkan koefisien regresi\n",
        "print(\"Koefisien Regresi:\")\n",
        "print(model.coef_)\n",
        "\n",
        "# Tampilkan intercept regresi\n",
        "print(\"Intercept Regresi:\")\n",
        "print(model.intercept_)\n",
        "\n"
      ]
    }
  ]
}